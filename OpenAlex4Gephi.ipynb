{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN60QXBhh0fECAr3M8wYjE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ifeanyi55/OpenAlex4Gephi/blob/main/OpenAlex4Gephi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to OpenAlex4Gephi**\n",
        "\n",
        "The OpenAlex4Gephi project is a project that allows a user to fetch network data from openalex.org in Gephi format via its API. The network data is a bimodal network of **authors to publications**. The network nodes and edges data are collected and stored as separate csv files, which can be downloaded to your local machine and then imported into Gephi for visualization and analysis."
      ],
      "metadata": {
        "id": "SbSWgHLCHr7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Package**"
      ],
      "metadata": {
        "id": "Rp5kt69gojly"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBbjVkjuB9X1"
      },
      "outputs": [],
      "source": [
        "# Install the openalexR package by running this code cell. Click the play button to run the cell or CTRL + Enter\n",
        "install.packages(\"openalexR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Keywords**\n",
        "If you are entering more than one keyword in the search parameter below, make sure to separate them by a comma.\n",
        "\n",
        "## **Dates**\n",
        "Dates inputs are always in the **yyyy-mm-dd** format.\n",
        "\n",
        "## **Run Code**\n",
        "To run the code after entering your search parameters, press the play button on the left of the code cell.\n"
      ],
      "metadata": {
        "id": "Z8PczPh_WOjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Enter Search Parameters & Run Cell to Generate Network Data (Nodes & Edges CSV Files)**"
      ],
      "metadata": {
        "id": "_gXbV9TGYzIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suppressWarnings(library(openalexR))\n",
        "\n",
        "authorPubNodes <- function(keywords,pub_start_date,pub_end_date){\n",
        "\n",
        "  keywords <- keywords\n",
        "  pub_start_date <- pub_start_date\n",
        "  pub_end_date <- pub_end_date\n",
        "\n",
        "  # create search engine function\n",
        "  search_engine <- function(keywords,pub_start_date,pub_end_date){\n",
        "    suppressPackageStartupMessages(library(openalexR))\n",
        "    suppressPackageStartupMessages(library(tidyverse))\n",
        "\n",
        "    options(openalexR.mailto = \"idiayeifeanyi@yahoo.com\",\n",
        "            openalexR.message = \"suppressed\")\n",
        "\n",
        "    # search engine\n",
        "    works_search <- oa_fetch(\n",
        "      entity = \"works\",\n",
        "      title.search = c(keywords),\n",
        "      cited_by_count = \">50\",\n",
        "      from_publication_date = pub_start_date,\n",
        "      to_publication_date = pub_end_date,\n",
        "      options = list(sort = \"cited_by_count:desc\"),\n",
        "      verbose = FALSE\n",
        "    )\n",
        "\n",
        "    return(works_search)\n",
        "\n",
        "  }\n",
        "\n",
        "  search_data <- search_engine(keywords,pub_start_date,pub_end_date)\n",
        "\n",
        "  # grab authors and group them according to collaboration\n",
        "  authors_collaboration_groups <- list()\n",
        "  for (i in 1:nrow(search_data)){\n",
        "    authors_collaboration_groups[[i]] <- search_data$author[[i]][2]\n",
        "  }\n",
        "\n",
        "  # grab all authors\n",
        "  all_authors <- c()\n",
        "  for (i in 1:length(authors_collaboration_groups)) {\n",
        "    all_authors <- c(all_authors,authors_collaboration_groups[[i]][[1]])\n",
        "  }\n",
        "\n",
        "  # get length of each authors collaboration\n",
        "  authors_length <- c()\n",
        "  for(authors in 1:length(authors_collaboration_groups)){\n",
        "    authors_length <- c(authors_length,authors_collaboration_groups[[authors]] |> nrow())\n",
        "  }\n",
        "\n",
        "  # grab all publications\n",
        "  publications <- list()\n",
        "  for (i in 1:nrow(search_data)){\n",
        "    publications[[i]] <- rep(search_data$display_name[i], each = authors_length[i])\n",
        " }\n",
        "\n",
        "  # place all publications in a vector\n",
        "  all_publications <- c()\n",
        "  for(i in 1:length(publications)){\n",
        "    all_publications <- c(all_publications,publications[[i]])\n",
        "  }\n",
        "\n",
        "  # create author_to_publication data frame\n",
        "  authors_to_publications <- data.frame(\n",
        "    Authors = all_authors,\n",
        "    Publications = all_publications\n",
        "  )\n",
        "\n",
        "  # stack the df so that authors and publications\n",
        "  # are together as one column\n",
        "  stacked_df <- stack(authors_to_publications)\n",
        "  stacked_df <- unique.data.frame(stacked_df) # remove duplicate rows\n",
        "  stacked_df <- stacked_df[-2] # delete second column in df\n",
        "\n",
        "  # create author_publications_nodes df\n",
        "  author_publication_nodes <- data.frame(\n",
        "    Id = 1:nrow(stacked_df),\n",
        "    Nodes = stacked_df$values,\n",
        "    Label = stacked_df$values\n",
        "  )\n",
        "\n",
        "\n",
        "  return(author_publication_nodes)\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Function for creating the network edges\n",
        "authorPubEdges <- function(keywords,pub_start_date,pub_end_date){\n",
        "\n",
        "  keywords <- keywords\n",
        "  pub_start_date <- pub_start_date\n",
        "  pub_end_date <- pub_end_date\n",
        "\n",
        "  # create search engine function\n",
        "  search_engine <- function(keywords,pub_start_date,pub_end_date){\n",
        "    suppressPackageStartupMessages(library(openalexR))\n",
        "    suppressPackageStartupMessages(library(tidyverse))\n",
        "\n",
        "    options(openalexR.mailto = \"idiayeifeanyi@yahoo.com\")\n",
        "\n",
        "    # search engine\n",
        "    works_search <- oa_fetch(\n",
        "      entity = \"works\",\n",
        "      title.search = c(keywords),\n",
        "      cited_by_count = \">50\",\n",
        "      from_publication_date = pub_start_date,\n",
        "      to_publication_date = pub_end_date,\n",
        "      options = list(sort = \"cited_by_count:desc\"),\n",
        "      verbose = FALSE\n",
        "    )\n",
        "\n",
        "    return(works_search)\n",
        "\n",
        "  }\n",
        "\n",
        "   # run author nodes function\n",
        "  author_nodes <- authorPubNodes(keywords,pub_start_date,pub_end_date)\n",
        "\n",
        "  # run search engine\n",
        "  search_data <- search_engine(keywords,pub_start_date,pub_end_date)\n",
        "\n",
        "\n",
        "  # grab authors and group them according to collaboration\n",
        "  authors_collaboration_groups <- list()\n",
        "  for (i in 1:nrow(search_data)){\n",
        "    authors_collaboration_groups[[i]] <- search_data$author[[i]][2]\n",
        "  }\n",
        "\n",
        "  # grab all authors\n",
        "  all_authors <- c()\n",
        "  for (i in 1:length(authors_collaboration_groups)) {\n",
        "    all_authors <- c(all_authors,authors_collaboration_groups[[i]][[1]])\n",
        "  }\n",
        "\n",
        "  # get length of each authors collaboration\n",
        "  authors_length <- c()\n",
        "  for(authors in 1:length(authors_collaboration_groups)){\n",
        "    authors_length <- c(authors_length,authors_collaboration_groups[[authors]] |> nrow())\n",
        "  }\n",
        "\n",
        "  # grab all publications\n",
        "  publications <- list()\n",
        "  for (i in 1:nrow(search_data)){\n",
        "    publications[[i]] <- rep(search_data$display_name[i], each = authors_length[i])\n",
        "  }\n",
        "\n",
        "  # place all publications in a vector\n",
        "  all_publications <- c()\n",
        "  for(i in 1:length(publications)){\n",
        "    all_publications <- c(all_publications,publications[[i]])\n",
        "  }\n",
        "\n",
        "  # create author_to_publication data frame\n",
        "  authors_to_publications <- data.frame(\n",
        "    Authors = all_authors,\n",
        "    Publications = all_publications\n",
        "  )\n",
        "\n",
        "  # create edges data frame\n",
        "  author_publication_edges <- data.frame(\n",
        "    Source = authors_to_publications$Authors,\n",
        "    Target = authors_to_publications$Publications,\n",
        "    Type = \"directed\",\n",
        "    Weight = 1.0\n",
        "  )\n",
        "\n",
        "\n",
        "  # replace edges with id from nodes data set\n",
        "  replace_edges_with_ids <- function(author_edges, author_nodes) {\n",
        "    # Create a lookup table for node values to their corresponding Ids\n",
        "    node_lookup <- setNames(author_nodes$Id, author_nodes$Node)\n",
        "\n",
        "    # Use the lookup table to replace Source and Target values in author_edges\n",
        "    author_edges$Source <- node_lookup[author_edges$Source]\n",
        "    author_edges$Target <- node_lookup[author_edges$Target]\n",
        "\n",
        "    return(author_edges)\n",
        "  }\n",
        "\n",
        "  # Call the function with your data frames\n",
        "  author_publication_edges <- replace_edges_with_ids(author_publication_edges, nodes_pub)\n",
        "\n",
        "  return(author_publication_edges)\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "Keywords <- \"\" # @param {type:\"string\"}\n",
        "Pub_start_date <- \"2024-02-01\" # @param {type:\"date\"}\n",
        "Pub_end_date <- \"2024-02-01\" # @param {type:\"date\"}\n",
        "\n",
        "# split keywords into a vector\n",
        "Keywords <- c(unlist(strsplit(Keywords,split = \",\")))\n",
        "\n",
        "# Run this code cell\n",
        "nodes_pub <- authorPubNodes(keywords = Keywords,\n",
        "                            pub_start_date = Pub_start_date,\n",
        "                            pub_end_date = Pub_end_date)\n",
        "\n",
        "edges_pub <- authorPubEdges(keywords = Keywords,\n",
        "                            pub_start_date = Pub_start_date,\n",
        "                            pub_end_date = Pub_end_date)\n",
        "\n",
        "\n",
        "# export nodes and edges csv files\n",
        "write.csv(nodes_pub,file = \"Nodes.csv\",row.names = F)\n",
        "write.csv(edges_pub,file = \"Edges.csv\",row.names = F)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AM7gEu3sJrdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To download the files, click the **Files** folder icon in the sidebar on the left of the notebook. There, you will see the generated csv files. Hover over each one and click on the 3 dots to download the file."
      ],
      "metadata": {
        "id": "1CZeAtuGehMs"
      }
    }
  ]
}